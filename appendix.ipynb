import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, confusion_matrix
import xgboost
from numpy import loadtxt
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn import tree
from sklearn import preprocessing


dataset = pd.read_csv('failory_100i.csv')


le = preprocessing.LabelEncoder()            
dataset = dataset.apply(le.fit_transform)       


print (dataset)


import pandas
import sklearn
import matplotlib.pyplot as plt
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

array = dataset.values

#Split the data into X and Y columns
    
X = array[:,0:23] # X axis data columns from first to the 23rd  column

Y = array[:,-1]   #Y axis data column, the last column


# prepare configuration for cross validation test harness
#Set the seed value
seed = 7

# prepare the different algorithms that will be used to build different models
models = []
models.append(('RF', RandomForestClassifier()))
models.append(('LR', LogisticRegression()))
models.append(('XT', ExtraTreesClassifier()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('SGD', SGDClassifier()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('ST', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC()))


results = []
names = []
scoring = 'accuracy'

for name, model in models:
	kfold = model_selection.KFold(n_splits=10, random_state=seed)
	cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)

fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()



import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
#from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, confusion_matrix

dataset = pd.read_csv('failory_100i.csv')   

dataset.columns  


import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
#from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, confusion_matrix
import xgboost
from numpy import loadtxt
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn import tree
from sklearn import preprocessing


dataset = pd.read_csv('failory_100i.csv') 


le = preprocessing.LabelEncoder()
dataset = dataset.apply(le.fit_transform)


print (dataset)


from xgboost import plot_importance
from matplotlib import pyplot

X = dataset.iloc[:,0:23].values
Y = dataset.iloc[:,-1].values   

seed = 72         
test_size = 0.1   

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)

model = XGBClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

print(model.feature_importances_)


plot_importance(model)
pyplot.show()


print('Feature Importances For Our XGBOOST Model Above\n')
for importance,feature in zip(model.feature_importances_,['index_i', 'Name', 'Category', 'Location', 'Year_of_Creation',
       'Year_of_Failure', 'Number_of_Founders', 'Number_of_Employees',
       'Number_of_Investors', 'Number_of_Funding_Rounds',
       'Total_Funding_Amount', 'Specific_Cause_of_Failure', 'Outcome',
       'blank_1', 'Number_of_Employees_unified',
       'UNIT_K_is_1-M_is_2-No_Data_is_3-Dash_is_4',
       'Currency_$_is_1_GBP_is_2_Euro_is_3_SEK_is_4', 'Decimal_point_position',
       'len', 'strip_currency', 'strip_units', 'Correct_figure_amount',
       'Correct_amount_in_USD',
       'Purchasing Power Parity_Factored_Funding_Amount' ]):
    print('{}: {}'.format(feature,importance))
